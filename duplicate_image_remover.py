#!/usr/bin/env python3
"""
YOLO í•™ìŠµìš© ì´ë¯¸ì§€ ì¤‘ë³µ ì œê±° ë„êµ¬
ìœ ì‚¬í•œ ì´ë¯¸ì§€ë“¤ì„ ì°¾ì•„ì„œ ì¤‘ë³µì„ ì œê±°í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import argparse
import shutil
import json
import csv
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Set, Tuple
from collections import defaultdict

try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    print("âš ï¸  ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•´ tqdm ì„¤ì¹˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤: pip install tqdm")

try:
    from imagededup.methods import PHash, DHash, AHash, WHash, CNN
    from imagededup.utils import plot_duplicates
except ImportError:
    print("imagededup ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
    print("pip install imagededup")
    exit(1)

# ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì
SUPPORTED_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}

class DuplicateImageRemover:
    def __init__(self, method='phash', threshold=3):
        """
        ì´ë¯¸ì§€ ì¤‘ë³µ ì œê±°ê¸° ì´ˆê¸°í™”
        
        Args:
            method: ì‚¬ìš©í•  í•´ì‹± ë°©ë²• ('phash', 'dhash', 'ahash', 'whash', 'cnn')
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (ë‚®ì„ìˆ˜ë¡ ë” ìœ ì‚¬í•œ ì´ë¯¸ì§€ë§Œ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨, 3 = 95% ìœ ì‚¬ë„)
        """
        self.threshold = threshold
        self.method_name = method
        
        # í•´ì‹± ë°©ë²• ì„ íƒ
        if method == 'phash':
            self.hasher = PHash()
        elif method == 'dhash':
            self.hasher = DHash()
        elif method == 'ahash':
            self.hasher = AHash()
        elif method == 'whash':
            self.hasher = WHash()
        elif method == 'cnn':
            self.hasher = CNN()
        else:
            raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë°©ë²•: {method}")
    
    def find_all_images(self, root_dir: str) -> List[str]:
        """
        ì§€ì •ëœ ë””ë ‰í† ë¦¬ì—ì„œ ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ëŠ”ë‹¤
        
        Args:
            root_dir: ê²€ìƒ‰í•  ë£¨íŠ¸ ë””ë ‰í† ë¦¬
            
        Returns:
            ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        print("ğŸ” ì´ë¯¸ì§€ íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
        image_files = []
        root_path = Path(root_dir)
        
        if not root_path.exists():
            raise FileNotFoundError(f"ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {root_dir}")
        
        # ëª¨ë“  íŒŒì¼ ê²½ë¡œ ìˆ˜ì§‘
        all_files = list(root_path.rglob('*'))
        
        # ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ì´ë¯¸ì§€ íŒŒì¼ í•„í„°ë§
        if TQDM_AVAILABLE:
            with tqdm(all_files, desc="ğŸ“‚ íŒŒì¼ ìŠ¤ìº”", unit="files") as pbar:
                for file_path in pbar:
                    if file_path.is_file() and file_path.suffix.lower() in SUPPORTED_EXTENSIONS:
                        image_files.append(str(file_path))
                        pbar.set_postfix(found=len(image_files))
        else:
            # tqdmì´ ì—†ì„ ë•ŒëŠ” ì£¼ê¸°ì ìœ¼ë¡œ ì§„í–‰ìƒí™© ì¶œë ¥
            for i, file_path in enumerate(all_files):
                if file_path.is_file() and file_path.suffix.lower() in SUPPORTED_EXTENSIONS:
                    image_files.append(str(file_path))
                
                # 10000ê°œë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
                if i % 10000 == 0 and i > 0:
                    print(f"   ìŠ¤ìº” ì¤‘... {i:,}ê°œ íŒŒì¼ í™•ì¸, {len(image_files):,}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
        
        print(f"âœ… ì´ {len(image_files):,}ê°œ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬")
        return sorted(image_files)
    
    def find_duplicates(self, image_dir: str) -> Dict[str, List[str]]:
        """
        ì¤‘ë³µ ì´ë¯¸ì§€ë¥¼ ì°¾ëŠ”ë‹¤
        
        Args:
            image_dir: ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” ë””ë ‰í† ë¦¬
            
        Returns:
            ì¤‘ë³µ ì´ë¯¸ì§€ ë§¤í•‘ (í‚¤: ëŒ€í‘œì´ë¯¸ì§€, ê°’: ì¤‘ë³µì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸)
        """
        print(f"\nğŸ” {self.method_name.upper()} ë°©ë²•ìœ¼ë¡œ ì´ë¯¸ì§€ í•´ì‹œ ìƒì„± ì¤‘...")
        start_time = time.time()
        
        # ì´ë¯¸ì§€ ì¸ì½”ë”© ìƒì„± (imagededup ë‚´ë¶€ì—ì„œ ì§„í–‰ë¥  í‘œì‹œ)
        try:
            encodings = self.hasher.encode_images(image_dir=image_dir)
        except Exception as e:
            print(f"âŒ ì¸ì½”ë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
        
        encoding_time = time.time() - start_time
        print(f"âœ… ì´ {len(encodings):,}ê°œ ì´ë¯¸ì§€ ì¸ì½”ë”© ì™„ë£Œ ({encoding_time:.1f}ì´ˆ ì†Œìš”)")
        
        # ì¤‘ë³µ ì°¾ê¸° ì‹œì‘
        print(f"\nğŸ”„ ì¤‘ë³µ ì´ë¯¸ì§€ íƒì§€ ì¤‘... (ì„ê³„ê°’: {self.threshold}, 95% ìœ ì‚¬ë„ ê¸°ì¤€)")
        comparison_start = time.time()
        
        if hasattr(self.hasher, 'find_duplicates') and self.method_name != 'cnn':
            # thresholdê°€ ì •ìˆ˜ì¸ì§€ í™•ì¸í•˜ê³  ë²”ìœ„ ì²´í¬
            threshold_int = int(self.threshold)
            if threshold_int < 0 or threshold_int > 64:
                raise ValueError(f"thresholdëŠ” 0-64 ì‚¬ì´ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ ê°’: {threshold_int}")
            
            duplicates = self.hasher.find_duplicates(
                encoding_map=encodings, 
                max_distance_threshold=threshold_int
            )
        else:
            duplicates = self.hasher.find_duplicates(encoding_map=encodings)
        
        comparison_time = time.time() - comparison_start
        
        # ì¤‘ë³µ í†µê³„ ê³„ì‚°
        total_duplicates = sum(len(dups) for dups in duplicates.values() if dups)
        duplicate_groups = len([k for k, v in duplicates.items() if v])
        
        print(f"âœ… ì¤‘ë³µ íƒì§€ ì™„ë£Œ ({comparison_time:.1f}ì´ˆ ì†Œìš”)")
        print(f"ğŸ“Š ë°œê²¬ëœ ì¤‘ë³µ: {duplicate_groups:,}ê°œ ê·¸ë£¹, {total_duplicates:,}ê°œ ì¤‘ë³µ ì´ë¯¸ì§€")
        
        return duplicates
    
    def group_duplicates(self, duplicates: Dict[str, List[str]]) -> List[Set[str]]:
        """
        ì¤‘ë³µ ì´ë¯¸ì§€ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ëŠ”ë‹¤
        
        Args:
            duplicates: imagededupì—ì„œ ë°˜í™˜ëœ ì¤‘ë³µ ë§¤í•‘
            
        Returns:
            ì¤‘ë³µ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸ (ê° ê·¸ë£¹ì€ ì¤‘ë³µëœ ì´ë¯¸ì§€ë“¤ì˜ ì§‘í•©)
        """
        # ëª¨ë“  ì¤‘ë³µ ê´€ê³„ë¥¼ ê·¸ë˜í”„ë¡œ ë§Œë“¤ê¸°
        graph = defaultdict(set)
        all_images = set()
        
        for main_image, duplicate_list in duplicates.items():
            if duplicate_list:  # ì¤‘ë³µì´ ìˆëŠ” ê²½ìš°ë§Œ
                all_images.add(main_image)
                for dup_image in duplicate_list:
                    all_images.add(dup_image)
                    graph[main_image].add(dup_image)
                    graph[dup_image].add(main_image)
        
        # ì—°ê²°ëœ ì»´í¬ë„ŒíŠ¸ ì°¾ê¸° (DFS)
        visited = set()
        groups = []
        
        for image in all_images:
            if image not in visited:
                group = set()
                stack = [image]
                
                while stack:
                    current = stack.pop()
                    if current not in visited:
                        visited.add(current)
                        group.add(current)
                        
                        # ì—°ê²°ëœ ëª¨ë“  ì´ë¯¸ì§€ ì¶”ê°€
                        for neighbor in graph[current]:
                            if neighbor not in visited:
                                stack.append(neighbor)
                
                if len(group) > 1:  # 2ê°œ ì´ìƒì¸ ê·¸ë£¹ë§Œ ì¶”ê°€
                    groups.append(group)
        
        return groups
    
    def select_representative(self, group: Set[str]) -> str:
        """
        ì¤‘ë³µ ê·¸ë£¹ì—ì„œ ëŒ€í‘œ ì´ë¯¸ì§€ë¥¼ ì„ ì •í•œë‹¤
        íŒŒì¼ í¬ê¸°ê°€ ê°€ì¥ í° ì´ë¯¸ì§€ë¥¼ ëŒ€í‘œë¡œ ì„ ì • (í™”ì§ˆì´ ì¢‹ì„ ê°€ëŠ¥ì„±)
        
        Args:
            group: ì¤‘ë³µ ì´ë¯¸ì§€ ê·¸ë£¹
            
        Returns:
            ëŒ€í‘œ ì´ë¯¸ì§€ ê²½ë¡œ
        """
        best_image = None
        best_size = 0
        
        for image_path in group:
            try:
                file_size = os.path.getsize(image_path)
                if file_size > best_size:
                    best_size = file_size
                    best_image = image_path
            except OSError:
                continue
        
        return best_image or list(group)[0]  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì„ íƒ
    
    def save_results_to_file(self, result: Dict, output_dir: str = "."):
        """
        ê²°ê³¼ë¥¼ JSONê³¼ CSV íŒŒì¼ë¡œ ì €ì¥í•œë‹¤
        
        Args:
            result: ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON íŒŒì¼ë¡œ ì €ì¥ (ìƒì„¸ ì •ë³´)
        json_filename = f"duplicate_analysis_{timestamp}.json"
        json_path = os.path.join(output_dir, json_filename)
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ ìƒì„¸ ê²°ê³¼ ì €ì¥: {json_filename}")
        
        # CSV íŒŒì¼ë¡œ ì €ì¥ (ì‚­ì œ ëŒ€ìƒ ëª©ë¡)
        if result.get("status") == "success" and result.get("groups"):
            csv_filename = f"duplicates_to_remove_{timestamp}.csv"
            csv_path = os.path.join(output_dir, csv_filename)
            
            with open(csv_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['ê·¸ë£¹ID', 'ëŒ€í‘œì´ë¯¸ì§€', 'ì‚­ì œëŒ€ìƒì´ë¯¸ì§€', 'íŒŒì¼í¬ê¸°(bytes)'])
                
                for group in result["groups"]:
                    representative = group["representative"]
                    for duplicate in group["duplicates"]:
                        try:
                            file_size = os.path.getsize(duplicate)
                        except:
                            file_size = 0
                        writer.writerow([
                            group["group_id"],
                            os.path.basename(representative),
                            duplicate,
                            file_size
                        ])
            
            print(f"ğŸ“Š ì‚­ì œ ëŒ€ìƒ ëª©ë¡: {csv_filename}")
        
        # ìš”ì•½ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
        summary_filename = f"duplicate_summary_{timestamp}.txt"
        summary_path = os.path.join(output_dir, summary_filename)
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¤‘ë³µ ë¶„ì„ ê²°ê³¼ ìš”ì•½\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ë°©ë²•: {self.method_name}\n")
            f.write(f"ì„ê³„ê°’: {self.threshold}\n\n")
            
            if result.get("status") == "success":
                f.write(f"ğŸ“Š í†µê³„:\n")
                f.write(f"   â€¢ ì „ì²´ ì´ë¯¸ì§€: {result['total_images']:,}ê°œ\n")
                f.write(f"   â€¢ ì¤‘ë³µ ê·¸ë£¹: {result['duplicate_groups']:,}ê°œ\n")
                f.write(f"   â€¢ ì¤‘ë³µ ì´ë¯¸ì§€: {result['total_duplicates']:,}ê°œ\n")
                f.write(f"   â€¢ ì‚­ì œ ëŒ€ìƒ: {result['total_to_remove']:,}ê°œ\n")
                f.write(f"   â€¢ ë³´ì¡´ ì´ë¯¸ì§€: {result['remaining_images']:,}ê°œ\n\n")
                
                # ìš©ëŸ‰ ì ˆì•½ ê³„ì‚°
                total_saved_size = 0
                for group in result.get("groups", []):
                    for dup_path in group["duplicates"]:
                        try:
                            total_saved_size += os.path.getsize(dup_path)
                        except:
                            pass
                
                if total_saved_size > 0:
                    saved_gb = total_saved_size / (1024**3)
                    f.write(f"ğŸ’¾ ì ˆì•½ ê°€ëŠ¥ ìš©ëŸ‰: {saved_gb:.2f} GB\n\n")
            
            elif result.get("status") == "no_duplicates":
                f.write("âœ… ì¤‘ë³µ ì´ë¯¸ì§€ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n")
        
        print(f"ğŸ“‹ ìš”ì•½ ë³´ê³ ì„œ: {summary_filename}")

    def process_duplicates(self, image_dir: str, delete: bool = False, 
                          backup_dir: str = None, save_results: bool = True) -> Dict:
        """
        ì¤‘ë³µ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•œë‹¤ (ì‚­ì œ ë˜ëŠ” ì •ë³´ ì¶œë ¥)
        
        Args:
            image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
            delete: Trueì´ë©´ ì‚­ì œ, Falseì´ë©´ ì •ë³´ë§Œ ì¶œë ¥
            backup_dir: ë°±ì—… ë””ë ‰í† ë¦¬ (ì‚­ì œ ì „ ë°±ì—…)
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ì •ë³´
        """
        # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        all_images = self.find_all_images(image_dir)
        print(f"ğŸ“‚ ì´ {len(all_images)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        if len(all_images) == 0:
            print("âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {"status": "no_images"}
        
        # ì¤‘ë³µ ì°¾ê¸°
        duplicates = self.find_duplicates(image_dir)
        
        # ì¤‘ë³µ ê·¸ë£¹ ìƒì„±
        duplicate_groups = self.group_duplicates(duplicates)
        
        if not duplicate_groups:
            print("âœ… ì¤‘ë³µ ì´ë¯¸ì§€ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {"status": "no_duplicates", "total_images": len(all_images)}
        
        # ê²°ê³¼ ì •ë³´ ìˆ˜ì§‘
        total_duplicates = 0
        total_to_remove = 0
        group_info = []
        
        for i, group in enumerate(duplicate_groups, 1):
            representative = self.select_representative(group)
            to_remove = group - {representative}
            
            group_data = {
                "group_id": i,
                "total_count": len(group),
                "representative": representative,
                "duplicates": list(to_remove),
                "remove_count": len(to_remove)
            }
            group_info.append(group_data)
            
            total_duplicates += len(group)
            total_to_remove += len(to_remove)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ì¤‘ë³µ ë¶„ì„ ê²°ê³¼:")
        print(f"   â€¢ ì „ì²´ ì´ë¯¸ì§€: {len(all_images)}ê°œ")
        print(f"   â€¢ ì¤‘ë³µ ê·¸ë£¹: {len(duplicate_groups)}ê°œ")
        print(f"   â€¢ ì¤‘ë³µ ì´ë¯¸ì§€: {total_duplicates}ê°œ")
        print(f"   â€¢ ì‚­ì œ ëŒ€ìƒ: {total_to_remove}ê°œ")
        print(f"   â€¢ ë³´ì¡´ ì´ë¯¸ì§€: {len(all_images) - total_to_remove}ê°œ")
        
        # ê·¸ë£¹ë³„ ìƒì„¸ ì •ë³´
        print(f"\nğŸ“‹ ê·¸ë£¹ë³„ ìƒì„¸ ì •ë³´:")
        for group_data in group_info:
            print(f"   ê·¸ë£¹ {group_data['group_id']}: {group_data['total_count']}ê°œ ì¤‘ {group_data['remove_count']}ê°œ ì‚­ì œ ì˜ˆì •")
            print(f"      ëŒ€í‘œ ì´ë¯¸ì§€: {os.path.basename(group_data['representative'])}")
            if len(group_data['duplicates']) <= 5:
                for dup in group_data['duplicates']:
                    print(f"      ì‚­ì œ ëŒ€ìƒ: {os.path.basename(dup)}")
            else:
                for dup in group_data['duplicates'][:3]:
                    print(f"      ì‚­ì œ ëŒ€ìƒ: {os.path.basename(dup)}")
                print(f"      ... ì™¸ {len(group_data['duplicates']) - 3}ê°œ")
            print()
        
        # ì‹¤ì œ ì‚­ì œ ìˆ˜í–‰
        deleted_count = 0
        if delete:
            if backup_dir:
                os.makedirs(backup_dir, exist_ok=True)
                print(f"ğŸ’¾ ë°±ì—… ë””ë ‰í† ë¦¬: {backup_dir}")
            
            print(f"\nğŸ—‘ï¸  íŒŒì¼ ì‚­ì œ ì‹œì‘...")
            
            # ì‚­ì œí•  ì „ì²´ íŒŒì¼ ìˆ˜ ê³„ì‚°
            total_to_delete = sum(len(group_data['duplicates']) for group_data in group_info)
            
            if TQDM_AVAILABLE:
                # tqdmìœ¼ë¡œ ì‚­ì œ ì§„í–‰ë¥  í‘œì‹œ
                with tqdm(total=total_to_delete, desc="ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ", unit="files") as pbar:
                    for group_data in group_info:
                        for img_path in group_data['duplicates']:
                            try:
                                # ë°±ì—…
                                if backup_dir:
                                    backup_path = os.path.join(backup_dir, os.path.basename(img_path))
                                    shutil.copy2(img_path, backup_path)
                                
                                # ì‚­ì œ
                                os.remove(img_path)
                                deleted_count += 1
                                pbar.set_postfix(deleted=deleted_count)
                                pbar.update(1)
                                
                            except Exception as e:
                                pbar.write(f"âŒ ì‚­ì œ ì‹¤íŒ¨ {os.path.basename(img_path)}: {e}")
            else:
                # tqdm ì—†ì„ ë•Œ ì£¼ê¸°ì  ì§„í–‰ë¥  ì¶œë ¥
                for group_data in group_info:
                    for img_path in group_data['duplicates']:
                        try:
                            # ë°±ì—…
                            if backup_dir:
                                backup_path = os.path.join(backup_dir, os.path.basename(img_path))
                                shutil.copy2(img_path, backup_path)
                            
                            # ì‚­ì œ
                            os.remove(img_path)
                            deleted_count += 1
                            
                            # 100ê°œë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
                            if deleted_count % 100 == 0:
                                print(f"   ì‚­ì œ ì§„í–‰ë¥ : {deleted_count:,}/{total_to_delete:,} ({deleted_count/total_to_delete*100:.1f}%)")
                            
                        except Exception as e:
                            print(f"âŒ ì‚­ì œ ì‹¤íŒ¨ {os.path.basename(img_path)}: {e}")
            
            print(f"\nâœ… ì‚­ì œ ì™„ë£Œ: {deleted_count:,}ê°œ íŒŒì¼")
        
        result = {
            "status": "success",
            "total_images": len(all_images),
            "duplicate_groups": len(duplicate_groups),
            "total_duplicates": total_duplicates,
            "total_to_remove": total_to_remove,
            "remaining_images": len(all_images) - total_to_remove,
            "groups": group_info,
            "deleted": deleted_count if delete else 0,
            "analysis_time": datetime.now().isoformat(),
            "method": self.method_name,
            "threshold": self.threshold,
            "source_directory": image_dir
        }
        
        # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        if save_results:
            self.save_results_to_file(result)
        
        return result

def main():
    parser = argparse.ArgumentParser(
        description="YOLO í•™ìŠµìš© ì´ë¯¸ì§€ ì¤‘ë³µ ì œê±° ë„êµ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python duplicate_image_remover.py /path/to/images --method phash
  python duplicate_image_remover.py /path/to/images --delete --backup ./backup
  python duplicate_image_remover.py /path/to/images --method cnn --threshold 0.9
        """
    )
    
    parser.add_argument('image_dir', help='ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--delete', action='store_true', 
                       help='ì¤‘ë³µ ì´ë¯¸ì§€ë¥¼ ì‹¤ì œë¡œ ì‚­ì œ (ê¸°ë³¸ê°’: False, ì •ë³´ë§Œ ì¶œë ¥)')
    parser.add_argument('--method', choices=['phash', 'dhash', 'ahash', 'whash', 'cnn'],
                       default='phash', help='ì¤‘ë³µ íƒì§€ ë°©ë²• (ê¸°ë³¸ê°’: phash)')
    parser.add_argument('--threshold', type=int, default=3,
                       help='ìœ ì‚¬ë„ ì„ê³„ê°’ (ë‚®ì„ìˆ˜ë¡ ë” ì—„ê²©, ê¸°ë³¸ê°’: 3 = 95%% ìœ ì‚¬ë„)')
    parser.add_argument('--backup', type=str,
                       help='ì‚­ì œ ì „ ë°±ì—…í•  ë””ë ‰í† ë¦¬ (--deleteì™€ í•¨ê»˜ ì‚¬ìš©)')
    
    args = parser.parse_args()
    
    # ì…ë ¥ ê²€ì¦
    if not os.path.exists(args.image_dir):
        print(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.image_dir}")
        return
    
    if args.delete and not args.backup:
        confirm = input("âš ï¸  ë°±ì—… ì—†ì´ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? ì‚­ì œëœ íŒŒì¼ì€ ë³µêµ¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (y/N): ")
        if confirm.lower() != 'y':
            print("ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
    
    try:
        # ì¤‘ë³µ ì œê±°ê¸° ìƒì„±
        remover = DuplicateImageRemover(method=args.method, threshold=args.threshold)
        
        print(f"ğŸš€ ì¤‘ë³µ ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘...")
        print(f"   â€¢ ë””ë ‰í† ë¦¬: {args.image_dir}")
        print(f"   â€¢ ë°©ë²•: {args.method}")
        print(f"   â€¢ ì„ê³„ê°’: {args.threshold}")
        print(f"   â€¢ ì‚­ì œ ëª¨ë“œ: {'ì˜ˆ' if args.delete else 'ì•„ë‹ˆì˜¤'}")
        if args.backup:
            print(f"   â€¢ ë°±ì—… ë””ë ‰í† ë¦¬: {args.backup}")
        print()
        
        # ì²˜ë¦¬ ì‹¤í–‰
        result = remover.process_duplicates(
            image_dir=args.image_dir,
            delete=args.delete,
            backup_dir=args.backup
        )
        
        if result["status"] == "success":
            print(f"\nğŸ‰ ì‘ì—… ì™„ë£Œ!")
            if args.delete:
                print(f"   â€¢ {result['deleted']}ê°œ íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                print(f"   â€¢ {result['remaining_images']}ê°œ íŒŒì¼ì´ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤.")
            else:
                print(f"   â€¢ {result['total_to_remove']}ê°œ íŒŒì¼ì´ ì‚­ì œ ëŒ€ìƒì…ë‹ˆë‹¤.")
                print(f"   â€¢ --delete ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì‚­ì œë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 